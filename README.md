
# Deepfake Detection Using GenConViT and FreqNet with Ensemble-Based Web Inference

> Ensemble-based deepfake detection system powered by GenConViT, FreqNet, and Vision Transformer. Includes a web-based inference interface using Flask for real-time image/video verification.

---

## Project Overview

The system integrates:
- **GenConViT Autoencoder + VAE** (Generative Convolutional Vision Transformer)
- **FreqNet** (Frequency-Aware CNN)
- **ViT** (Vision Transformer from HuggingFace)

It combines **spatial**, **frequency**, and **latent representation** learning to classify media as `REAL` or `FAKE`.

---

## üñºÔ∏è System Architecture

### Fig. 1 ‚Äì Architecture Diagram
![Architecture Diagram](assets/fig1_architecture.png)

---

## DetectApp Web Interface

DetectApp is a Flask-based frontend allowing users to upload images or videos and view authenticity predictions.

### Fig. 2 ‚Äì Landing Page with Carousel and Features
![Landing Page](assets/fig2_landing.png)

### Fig. 3 ‚Äì Upload and About Section
![Upload Interface](assets/fig3_upload_about.png)

### Fig. 4 ‚Äì Result Page with Prediction Outcome
![Prediction Result](assets/fig4_result.png)

### Fig. 5 ‚Äì Individual Model Predictions
![Model Predictions](assets/fig5_model_predictions.png)

---

## Features

- Multi-model inference (GenConViT, FreqNet, ViT)
- Image and Video support (`.jpg`, `.png`, `.mp4`, `.avi`)
- Fast frame-level detection
- Secure file handling
- Mobile-responsive web interface

---

## üõ†Ô∏è Installation Instructions

### 2. Install Dependencies

Create a virtual environment and install all required dependencies:

```bash
# Create a virtual environment
python -m venv venv

# Activate the environment
# On macOS/Linux:
source venv/bin/activate

# On Windows:
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

---

### 4. Run the Web App

After installing the dependencies and activating the virtual environment:

```bash
python app.py
```



---

## Dataset Used

### Deepfake-TIMIT (Video-Based)

- **Total Videos**: 10,240  
  - 320 real  
  - 9,920 deepfakes  
- **Frame Rate**: 25 frames per second  
- **Video Duration**: ~3 seconds each  
- **Total Image Frames**: ~768,000 frames

---

## Results and Evaluation

| Model       | Dataset Scope            | Accuracy     |
|-------------|---------------------------|--------------|
| GenConViT   | In-domain (video)         | ~98%         |
| FreqNet     | Cross-GAN (17 generators) | 92.8% (mean) |
| ViT         | Independent image dataset | ~70%         |

---

## Model Inference Summary

| Model            | Input Type  | Method             | Output      |
|------------------|------------ |--------------------|-------------|
| GenConViT-AE     | Image/Video | Reconstruction     | Real/Fake   |
| GenConViT-VAE    | Image/Video | Latent Analysis    | Real/Fake   |
| FreqNet          | Image/Video | FFT-based Learning | Real/Fake   |
| ViT              | Image       | Transformer-Based  | Real/Fake   |

### Ensemble Voting
- Majority voting across 4 models.
- Confidence is averaged from all model outputs.

---

## üåç Acknowledgements

- [GenConViT Paper](https://arxiv.org/abs/2307.07036)  
- [FreqNet Paper](https://arxiv.org/abs/2403.07240)  
- [Hugging Face ViT Model](https://huggingface.co/google/vit-base-patch16-224-in21k)
